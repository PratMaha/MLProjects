{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always import\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "# numpy & scipy\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import pairwise_distances_argmin, pairwise_distances\n",
    "from sklearn.metrics.cluster import homogeneity_score, completeness_score, v_measure_score, adjusted_rand_score, adjusted_mutual_info_score\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Hungarian algorithm\n",
    "from munkres import Munkres\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# visuals\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "from sklearn.manifold import Isomap, TSNE\n",
    "\n",
    "# maybe\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST data and normalization\n",
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, data_home='mnist/')\n",
    "y = np.asarray(list(map(int, y)))\n",
    "X = np.asarray(X.astype(float))\n",
    "X = scale(X)\n",
    "n_digits = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Hungarian algorithm\n",
    "def calculate_hungarian_cost_matrix(y_true, y_pred, K) :\n",
    "    conf_mat = confusion_matrix(y_true, y_pred, labels=range(K))\n",
    "    #print(conf_mat.max())\n",
    "    cost_matrix = (conf_mat.max() - conf_mat)/conf_mat.max()\n",
    "    return cost_matrix\n",
    "\n",
    "def accuracy(pred, y):\n",
    "    dataset_size = y.size\n",
    "    correct_predictions = 0\n",
    "    #print(pred)\n",
    "    #print(y)\n",
    "    for i in range(dataset_size):\n",
    "        if y[i] == (pred[i]):\n",
    "            correct_predictions += 1\n",
    "    precision = (correct_predictions/dataset_size)*100\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Using the Forgy seed method for initialisation : take K random datapoints from the dataset\\ninitial_centroid_indices = np.random.choice(num_samples, K, replace=False)\\ncentroids = X[initial_centroid_indices][:]\\n#print(initial_centroid_indices)\\n[final_kmeans_centroids, new_cost] = run_kmeans(K, centroids, X)\\n#print(final_kmeans_solution[0])\\ndistance_matrix = get_distance_matrix(X, final_kmeans_centroids)\\ny_pred = np.argmin(distance_matrix, axis = 1)\\nhomogeneity_score = metrics.homogeneity_score(y, y_pred)\\nprint(\"Homogeneity Score (using Forgy method): \" + str(homogeneity_score))\\ncompleteness_score = metrics.completeness_score(y, y_pred)\\nprint(\"Completeness Score (using Forgy method): \" + str(completeness_score))\\nvmeasure_score = metrics.v_measure_score(y, y_pred)\\nprint(\"V-Measure Score (using Forgy method): \" + str(vmeasure_score))\\nadjusted_rand_score = metrics.adjusted_rand_score(y, y_pred)\\nprint(\"Adjusted Rand Score (using Forgy method): \" + str(adjusted_rand_score))\\nadjusted_mutual_info_score = metrics.adjusted_mutual_info_score(y, y_pred)\\nprint(\"Adjusted Rand Score (using Forgy method): \" + str(adjusted_mutual_info_score))\\ncost_matrix = calculate_hungarian_cost_matrix(y, y_pred, K)\\n#print(cost_matrix)\\ncluster_to_class_matching = {}\\nrow_ind, col_ind = linear_sum_assignment(cost_matrix)\\nfor row, column in zip(row_ind, col_ind):\\n    print(f\"Cluster {row} assigned to Class {column} \")\\n    cluster_to_class_matching[row] = column\\nfor original_value, new_value in cluster_to_class_matching.items():\\n    y_pred[y_pred == original_value] = new_value + 10\\ny_pred = y_pred - 10\\ncm = confusion_matrix(y, y_pred, labels=range(K))\\nprint(cm)\\nacc = accuracy(y_pred, y)\\nprint(\"Accuracy : \" + str(acc))\\nprint (\"NOTE : THESE VALUES DO NOT CORRESPOND TO ANY ANSWER AND WERE SIMPLY USED FOR TESTING K-MEANS\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Kmeans\n",
    "def get_distance_matrix(X, C):\n",
    "    return (np.sqrt(((X[:,np.newaxis,:] - C) ** 2).sum(axis=2)))\n",
    "\n",
    "def calculate_cost(centroids, X, min_index_matrix):\n",
    "    return ((X - centroids[min_index_matrix]) ** 2).sum()\n",
    "    \n",
    "def run_kmeans(K, initial_centroids, X):\n",
    "    num_samples, num_features = X.shape\n",
    "    #print(centroids[0])\n",
    "    #print(centroids.shape)\n",
    "    centroids = initial_centroids.copy()\n",
    "    distance_matrix = get_distance_matrix(X, centroids)\n",
    "    max_iter = 300\n",
    "    epsilon = 0.00001\n",
    "    iter = 0\n",
    "    old_cost = 0\n",
    "    min_index_matrix = np.argmin(distance_matrix, axis = 1)\n",
    "    new_cost = calculate_cost(centroids, X, min_index_matrix)\n",
    "    #print(\"New Cost : \" + str(new_cost))\n",
    "    while iter <= max_iter and abs(new_cost-old_cost) >= epsilon :\n",
    "        #print(\"Iteration : \" + str(iter))\n",
    "        #print(centroids)\n",
    "        for j in range(K):\n",
    "            jcluster_indices = np.array(min_index_matrix == j)\n",
    "            jcluster = X[jcluster_indices, :]\n",
    "            if jcluster.shape[0] > 0 :\n",
    "                centroids[j,:] = jcluster.sum(axis=0)/jcluster.shape[0]\n",
    "        distance_matrix = get_distance_matrix(X, centroids)\n",
    "        min_index_matrix = np.argmin(distance_matrix, axis = 1)\n",
    "        old_cost = new_cost\n",
    "        new_cost = calculate_cost(centroids, X, min_index_matrix)\n",
    "        iter = iter + 1\n",
    "    return [centroids, new_cost]\n",
    "\n",
    "\n",
    "#print (\"NOTE : THESE VALUES DO NOT CORRESPOND TO ANY ANSWER AND WERE SIMPLY USED FOR TESTING K-MEANS\")\n",
    "num_samples, num_features = X.shape\n",
    "K = 10\n",
    "'''\n",
    "#Using the Forgy seed method for initialisation : take K random datapoints from the dataset\n",
    "initial_centroid_indices = np.random.choice(num_samples, K, replace=False)\n",
    "centroids = X[initial_centroid_indices][:]\n",
    "#print(initial_centroid_indices)\n",
    "[final_kmeans_centroids, new_cost] = run_kmeans(K, centroids, X)\n",
    "#print(final_kmeans_solution[0])\n",
    "distance_matrix = get_distance_matrix(X, final_kmeans_centroids)\n",
    "y_pred = np.argmin(distance_matrix, axis = 1)\n",
    "homogeneity_score = metrics.homogeneity_score(y, y_pred)\n",
    "print(\"Homogeneity Score (using Forgy method): \" + str(homogeneity_score))\n",
    "completeness_score = metrics.completeness_score(y, y_pred)\n",
    "print(\"Completeness Score (using Forgy method): \" + str(completeness_score))\n",
    "vmeasure_score = metrics.v_measure_score(y, y_pred)\n",
    "print(\"V-Measure Score (using Forgy method): \" + str(vmeasure_score))\n",
    "adjusted_rand_score = metrics.adjusted_rand_score(y, y_pred)\n",
    "print(\"Adjusted Rand Score (using Forgy method): \" + str(adjusted_rand_score))\n",
    "adjusted_mutual_info_score = metrics.adjusted_mutual_info_score(y, y_pred)\n",
    "print(\"Adjusted Rand Score (using Forgy method): \" + str(adjusted_mutual_info_score))\n",
    "cost_matrix = calculate_hungarian_cost_matrix(y, y_pred, K)\n",
    "#print(cost_matrix)\n",
    "cluster_to_class_matching = {}\n",
    "row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "for row, column in zip(row_ind, col_ind):\n",
    "    print(f\"Cluster {row} assigned to Class {column} \")\n",
    "    cluster_to_class_matching[row] = column\n",
    "for original_value, new_value in cluster_to_class_matching.items():\n",
    "    y_pred[y_pred == original_value] = new_value + 10\n",
    "y_pred = y_pred - 10\n",
    "cm = confusion_matrix(y, y_pred, labels=range(K))\n",
    "print(cm)\n",
    "acc = accuracy(y_pred, y)\n",
    "print(\"Accuracy : \" + str(acc))\n",
    "print (\"NOTE : THESE VALUES DO NOT CORRESPOND TO ANY ANSWER AND WERE SIMPLY USED FOR TESTING K-MEANS\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section 2 a/b) - I\n",
      "Homogeneity Score (using top K principal eigenvectors of PCA): 0.4197975269152666\n",
      "Completeness Score (using top K principal eigenvectors of PCA): 0.4419190420959369\n",
      "V-Measure Score (using top K principal eigenvectors of PCA): 0.43057433880263696\n",
      "Adjusted Rand Score (using top K principal eigenvectors of PCA): 0.32075816979535976\n",
      "Adjusted Rand Score (using top K principal eigenvectors of PCA): 0.4304273983543338\n",
      "Class to Cluster Assignments based on Hungarian Algorithm\n",
      "Class 0 assigned to Cluster 0 \n",
      "Class 1 assigned to Cluster 4 \n",
      "Class 2 assigned to Cluster 2 \n",
      "Class 3 assigned to Cluster 5 \n",
      "Class 4 assigned to Cluster 9 \n",
      "Class 5 assigned to Cluster 8 \n",
      "Class 6 assigned to Cluster 3 \n",
      "Class 7 assigned to Cluster 7 \n",
      "Class 8 assigned to Cluster 6 \n",
      "Class 9 assigned to Cluster 1 \n",
      "Confusion Matrix on predictions post matching : \n",
      "[[3876   35  118 1356   13  658  351    6  480   10]\n",
      " [   0 7638   13   27    8  159   16    5   10    1]\n",
      " [  40  827 2380  726  185   85  862   29 1815   41]\n",
      " [  10  577  734 4097  200  118   88   95 1117  105]\n",
      " [  55  536   73    5 3968  948  128  741   27  343]\n",
      " [  33  467  246 2131  311 2709  102   93  158   63]\n",
      " [ 282  561  423  109   27  133 5323    1   12    5]\n",
      " [  20  516   16    9 1580  134    3 4086   13  916]\n",
      " [  45 1171  205 2589  355 2096   31  182   78   73]\n",
      " [  44  331   23  124 3487  131    5 2368   14  431]]\n",
      "Accuracy : 49.40857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"Section 2 a/b) - I\")\n",
    "pca = PCA(n_components=K)\n",
    "pca.fit(X)\n",
    "centroids = pca.components_\n",
    "[final_kmeans_centroids, new_cost] = run_kmeans(K, centroids, X)\n",
    "#print(final_kmeans_solution[0])\n",
    "distance_matrix = get_distance_matrix(X, final_kmeans_centroids)\n",
    "y_pred = np.argmin(distance_matrix, axis = 1)\n",
    "homogeneity_score = metrics.homogeneity_score(y, y_pred)\n",
    "print(\"Homogeneity Score (using top K principal eigenvectors of PCA): \" + str(homogeneity_score))\n",
    "completeness_score = metrics.completeness_score(y, y_pred)\n",
    "print(\"Completeness Score (using top K principal eigenvectors of PCA): \" + str(completeness_score))\n",
    "vmeasure_score = metrics.v_measure_score(y, y_pred)\n",
    "print(\"V-Measure Score (using top K principal eigenvectors of PCA): \" + str(vmeasure_score))\n",
    "adjusted_rand_score = metrics.adjusted_rand_score(y, y_pred)\n",
    "print(\"Adjusted Rand Score (using top K principal eigenvectors of PCA): \" + str(adjusted_rand_score))\n",
    "adjusted_mutual_info_score = metrics.adjusted_mutual_info_score(y, y_pred)\n",
    "print(\"Adjusted Rand Score (using top K principal eigenvectors of PCA): \" + str(adjusted_mutual_info_score))\n",
    "cost_matrix = calculate_hungarian_cost_matrix(y, y_pred, K)\n",
    "#print(cost_matrix)\n",
    "cluster_to_class_matching = {}\n",
    "row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "print(\"Class to Cluster Assignments based on Hungarian Algorithm\")\n",
    "for row, column in zip(row_ind, col_ind):\n",
    "    print(f\"Class {row} assigned to Cluster {column} \")\n",
    "    cluster_to_class_matching[column] = row\n",
    "for original_value, new_value in cluster_to_class_matching.items():\n",
    "    y_pred[y_pred == original_value] = new_value + 10\n",
    "y_pred = y_pred - 10\n",
    "print(\"Confusion Matrix on predictions post matching : \")\n",
    "cm = confusion_matrix(y, y_pred, labels=range(K))\n",
    "print(cm)\n",
    "acc = accuracy(y_pred, y)\n",
    "print(\"Accuracy : \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section 2 a/b) - II\n",
      "Homogeneity Score (using PCA for dimensionality reduction to d = 30): 0.4222313136385659\n",
      "Completeness Score (using PCA for dimensionality reduction to d = 30): 0.4439863964506075\n",
      "V-Measure Score (using PCA for dimensionality reduction to d = 30): 0.43283566527794587\n",
      "Adjusted Rand Score (using PCA for dimensionality reduction to d = 30): 0.32192715104290953\n",
      "Adjusted Rand Score (using PCA for dimensionality reduction to d = 30): 0.43268938916389627\n",
      "Class to Cluster Assignments based on Hungarian Algorithm\n",
      "Class 0 assigned to Cluster 7 \n",
      "Class 1 assigned to Cluster 1 \n",
      "Class 2 assigned to Cluster 5 \n",
      "Class 3 assigned to Cluster 6 \n",
      "Class 4 assigned to Cluster 0 \n",
      "Class 5 assigned to Cluster 2 \n",
      "Class 6 assigned to Cluster 4 \n",
      "Class 7 assigned to Cluster 9 \n",
      "Class 8 assigned to Cluster 8 \n",
      "Class 9 assigned to Cluster 3 \n",
      "Confusion Matrix on predictions post matching : \n",
      "[[3965   35   82  942   20  658  763    7  418   13]\n",
      " [   0 7621   13   29    5  173   16    7   12    1]\n",
      " [  42  839 2588  775  165   92  673   42 1717   57]\n",
      " [  11  678  219 4440  187  152   97   91 1141  125]\n",
      " [  50  543   49    3 3938  905  159  677   25  475]\n",
      " [  35  529  128 2061  326 2798  129   70  157   80]\n",
      " [ 240  504  774   53   37  132 5120    1    9    6]\n",
      " [  19  552    7   14 1584  114    3 4072   17  911]\n",
      " [  48 1348   96 2220  398 2297   53  180   78  107]\n",
      " [  42  361   15  106 3502  118    6 2275   15  518]]\n",
      "Accuracy : 50.197142857142865\n"
     ]
    }
   ],
   "source": [
    "print(\"Section 2 a/b) - II\")\n",
    "d = 30\n",
    "pca = PCA(n_components=d)\n",
    "X_pca = pca.fit_transform(X)\n",
    "#print(X_pca.shape)\n",
    "no_of_runs = 10\n",
    "cost = 100000000\n",
    "final_centroids = np.zeros((K, d))\n",
    "for i in range(no_of_runs) :\n",
    "    #Using the Forgy seed method for initialisation : take K random datapoints from PCA-applied dataset\n",
    "    rs = 5*i\n",
    "    np.random.seed(rs)\n",
    "    initial_centroid_indices = np.random.choice(num_samples, K, replace=False)\n",
    "    centroids = X_pca[initial_centroid_indices][:]\n",
    "    #print(centroids.shape)\n",
    "    [final_kmeans_centroids, new_cost] = run_kmeans(K, centroids, X_pca)\n",
    "    if cost > new_cost :\n",
    "        cost = new_cost\n",
    "        final_centroids = final_kmeans_centroids.copy()\n",
    "distance_matrix = get_distance_matrix(X_pca, final_centroids)\n",
    "y_pred = np.argmin(distance_matrix, axis = 1)\n",
    "homogeneity_score = metrics.homogeneity_score(y, y_pred)\n",
    "print(\"Homogeneity Score (using PCA for dimensionality reduction to d = 30): \" + str(homogeneity_score))\n",
    "completeness_score = metrics.completeness_score(y, y_pred)\n",
    "print(\"Completeness Score (using PCA for dimensionality reduction to d = 30): \" + str(completeness_score))\n",
    "vmeasure_score = metrics.v_measure_score(y, y_pred)\n",
    "print(\"V-Measure Score (using PCA for dimensionality reduction to d = 30): \" + str(vmeasure_score))\n",
    "adjusted_rand_score = metrics.adjusted_rand_score(y, y_pred)\n",
    "print(\"Adjusted Rand Score (using PCA for dimensionality reduction to d = 30): \" + str(adjusted_rand_score))\n",
    "adjusted_mutual_info_score = metrics.adjusted_mutual_info_score(y, y_pred)\n",
    "print(\"Adjusted Rand Score (using PCA for dimensionality reduction to d = 30): \" + str(adjusted_mutual_info_score)) \n",
    "cost_matrix = calculate_hungarian_cost_matrix(y, y_pred, K)\n",
    "#print(cost_matrix)\n",
    "cluster_to_class_matching = {}\n",
    "row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "print(\"Class to Cluster Assignments based on Hungarian Algorithm\")\n",
    "for row, column in zip(row_ind, col_ind):\n",
    "    print(f\"Class {row} assigned to Cluster {column} \")\n",
    "    cluster_to_class_matching[column] = row\n",
    "for original_value, new_value in cluster_to_class_matching.items():\n",
    "    y_pred[y_pred == original_value] = new_value + 10\n",
    "y_pred = y_pred - 10\n",
    "cm = confusion_matrix(y, y_pred, labels=range(K))\n",
    "print(\"Confusion Matrix on predictions post matching : \")\n",
    "print(cm)\n",
    "acc = accuracy(y_pred, y)\n",
    "print(\"Accuracy : \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Clustering Results :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prateek/anaconda3/envs/AnacondaTest/lib/python3.11/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "/Users/prateek/anaconda3/envs/AnacondaTest/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:394: SparseEfficiencyWarning: splu converted its input to CSC format\n",
      "  warn('splu converted its input to CSC format', SparseEfficiencyWarning)\n",
      "/Users/prateek/anaconda3/envs/AnacondaTest/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:285: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
      "  warn('spsolve is more efficient when sparse b '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity Score (using spectral clustering): 0.5987127729924084\n",
      "Completeness Score (using spectral clustering): 0.6694485180155375\n",
      "V-Measure Score (using spectral clustering): 0.6321078894912106\n",
      "Adjusted Rand Score (using spectral clustering): 0.4677415369830309\n",
      "Adjusted Rand Score (using spectral clustering): 0.6320129377410119\n",
      "Class to Cluster Assignments based on Hungarian Algorithm\n",
      "Class 0 assigned to Cluster 9 \n",
      "Class 1 assigned to Cluster 6 \n",
      "Class 2 assigned to Cluster 1 \n",
      "Class 3 assigned to Cluster 0 \n",
      "Class 4 assigned to Cluster 7 \n",
      "Class 5 assigned to Cluster 3 \n",
      "Class 6 assigned to Cluster 8 \n",
      "Class 7 assigned to Cluster 2 \n",
      "Class 8 assigned to Cluster 4 \n",
      "Class 9 assigned to Cluster 5 \n",
      "Confusion Matrix on predictions post matching : \n",
      "[[6475    3   70   70    0    0   22    1  233   29]\n",
      " [   0 4396   28   21 3333    0    7    1   62   29]\n",
      " [  57   35 5861  362   12    0   44   38  473  108]\n",
      " [  11   10  185 6049   53    0    1   47  603  182]\n",
      " [   3   28  116   23   29    1   11   10   50 6553]\n",
      " [  44    4 1542 1803    8    0   19    6 2631  256]\n",
      " [ 104   12   95   29    7    0 3639    0 2939   51]\n",
      " [  10   88   44   38   43    1    0 4150   29 2890]\n",
      " [  47   40  351  945   28    0    3    6 5149  256]\n",
      " [  20   10   32   97   31    0    0   96   70 6602]]\n",
      "Accuracy : 60.5\n"
     ]
    }
   ],
   "source": [
    "# TODO: Spectral clustering\n",
    "def spectral_clustering_analysis(X_pca):\n",
    "    # k is number of nearest neighbours in the KNN model, K is the number of clusters in k_means\n",
    "    k = 500\n",
    "    H = neighbors.NearestNeighbors(n_neighbors=k, algorithm='kd_tree', metric='euclidean').fit(X_pca).kneighbors_graph(mode='distance')\n",
    "    #print(E.shape)\n",
    "    sigma = H.sum()/H.nnz\n",
    "    H = H.power(2)\n",
    "    E = -H.multiply(1.0/(2*sigma*sigma))\n",
    "    #print(\"norm done\")\n",
    "    #print(E)\n",
    "    #print(scipy.sparse.issparse(E))\n",
    "    E.data = np.exp(E.data)\n",
    "    #print(\"exp done\")\n",
    "    #print(E)\n",
    "    E.setdiag(values=0)\n",
    "    #print(E)\n",
    "    #total_sum = E.sum()\n",
    "    #E = E.multiply(1.0/total_sum)\n",
    "    row_sums = E.sum(axis=1)\n",
    "    row_sums = np.ravel(row_sums)\n",
    "    row_sums_reciprocal = np.reciprocal(row_sums, where=row_sums!=0)\n",
    "    E = E.multiply(row_sums_reciprocal[:, np.newaxis])\n",
    "    E.setdiag(values=1)\n",
    "    #print(E)\n",
    "    E_transpose = E.transpose()\n",
    "    E = (E + E_transpose)\n",
    "    E = E.multiply(0.5)\n",
    "    #print(E)\n",
    "    D = scipy.sparse.csr_array((E.shape))\n",
    "    D.setdiag(E.sum(axis=1))\n",
    "    #print(D)\n",
    "    D_L = D.sqrt()\n",
    "    D_L = scipy.sparse.linalg.inv(D_L)\n",
    "    L = -D_L @ E @ D_L\n",
    "    L_r, L_c = L.shape\n",
    "    L = scipy.sparse.identity(L_r, format='csr') + L\n",
    "    #print(L.shape)\n",
    "    #print(L)\n",
    "    no_of_eigenvectors = 20\n",
    "    #print(\"Start Eigen Analysis\")\n",
    "    eigenvalues, eigenvectors = scipy.sparse.linalg.eigs(L, k=no_of_eigenvectors, which='SR')\n",
    "    #print(eigenvectors)\n",
    "    idx = np.argsort(eigenvalues.real)\n",
    "    sorted_eigen_values = eigenvalues[idx]\n",
    "    sorted_eigen_vectors = eigenvectors.real[:,idx]\n",
    "    k_eigen_vectors = sorted_eigen_vectors[:,1:]\n",
    "    return [sorted_eigen_values, k_eigen_vectors]\n",
    "\n",
    "print(\"Spectral Clustering Results :\")\n",
    "[sorted_eigen_values, k_eigen_vectors] = spectral_clustering_analysis(X_pca)\n",
    "y_pred = KMeans(init='k-means++', n_clusters=10, n_init=10).fit_predict(k_eigen_vectors)\n",
    "homogeneity_score = metrics.homogeneity_score(y, y_pred)\n",
    "print(\"Homogeneity Score (using spectral clustering): \" + str(homogeneity_score))\n",
    "completeness_score = metrics.completeness_score(y, y_pred)\n",
    "print(\"Completeness Score (using spectral clustering): \" + str(completeness_score))\n",
    "vmeasure_score = metrics.v_measure_score(y, y_pred)\n",
    "print(\"V-Measure Score (using spectral clustering): \" + str(vmeasure_score))\n",
    "adjusted_rand_score = metrics.adjusted_rand_score(y, y_pred)\n",
    "print(\"Adjusted Rand Score (using spectral clustering): \" + str(adjusted_rand_score))\n",
    "adjusted_mutual_info_score = metrics.adjusted_mutual_info_score(y, y_pred)\n",
    "print(\"Adjusted Rand Score (using spectral clustering): \" + str(adjusted_mutual_info_score))\n",
    "cost_matrix = calculate_hungarian_cost_matrix(y, y_pred, 10)\n",
    "#print(cost_matrix)\n",
    "#print(sorted_eigen_values)\n",
    "#print(k_eigen_vectors.shape)\n",
    "cluster_to_class_matching = {}\n",
    "row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "print(\"Class to Cluster Assignments based on Hungarian Algorithm\")\n",
    "for row, column in zip(row_ind, col_ind):\n",
    "    print(f\"Class {row} assigned to Cluster {column} \")\n",
    "    cluster_to_class_matching[column] = row\n",
    "for original_value, new_value in cluster_to_class_matching.items():\n",
    "    y_pred[y_pred == original_value] = new_value + 10\n",
    "y_pred = y_pred - 10\n",
    "print(\"Confusion Matrix on predictions post matching : \")\n",
    "cm = confusion_matrix(y, y_pred, labels=range(10))\n",
    "print(cm)\n",
    "acc = accuracy(y_pred, y)\n",
    "print(\"Accuracy : \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans + kNN Results :\n",
      "Training Accuracy for Kmeans+knn for k = 1 : 100.0\n",
      "Testing Accuracy for Kmeans+knn for k = 1 : 82.00286123032903\n",
      "Training Accuracy for Kmeans+knn for k = 3 : 93.0\n",
      "Testing Accuracy for Kmeans+knn for k = 3 : 77.81545064377683\n",
      "Training Accuracy for Kmeans+knn for k = 5 : 88.0\n",
      "Testing Accuracy for Kmeans+knn for k = 5 : 76.03290414878397\n"
     ]
    }
   ],
   "source": [
    "# TODO: Clustering + KNN\n",
    "def euclidean_distance(row1, row2):\n",
    "    distance = np.linalg.norm(row1 - row2)\n",
    "    return distance\n",
    "\n",
    "def knn(X_train, y_train, X_test, kvalue):\n",
    "    y_pred = []\n",
    "    for x in X_test :\n",
    "        distances = [euclidean_distance(x, x_train) for x_train in X_train]\n",
    "        k_indices = np.argsort(distances)[:kvalue]\n",
    "        k_nearest_labels = [y_train[i] for i in k_indices]\n",
    "        most_common = np.argmax(np.bincount(k_nearest_labels))\n",
    "        y_pred.append(most_common)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "no_of_runs = 10\n",
    "cost = 100000000\n",
    "K_d_cluster_size=100\n",
    "k_values = [1,3,5]\n",
    "final_centroids = np.zeros((K, d))\n",
    "for i in range(no_of_runs) :\n",
    "    #Using the Forgy seed method for initialisation : take K random datapoints from PCA-applied dataset\n",
    "    rs = 5*i\n",
    "    np.random.seed(rs)\n",
    "    initial_centroid_indices = np.random.choice(num_samples, K_d_cluster_size, replace=False)\n",
    "    centroids = X_pca[initial_centroid_indices][:]\n",
    "    #print(centroids.shape)\n",
    "    [final_kmeans_centroids, new_cost] = run_kmeans(K_d_cluster_size, centroids, X_pca)\n",
    "    #print(cost)\n",
    "    if cost > new_cost :\n",
    "        cost = new_cost\n",
    "        final_centroids = final_kmeans_centroids.copy()\n",
    "distance_matrix = get_distance_matrix(X_pca, final_centroids)\n",
    "min_row_indices = np.argmin(distance_matrix, axis=0)\n",
    "final_knn_train_X = X_pca[min_row_indices][:]\n",
    "final_knn_train_y = y[min_row_indices][:]\n",
    "final_knn_test_X = np.delete(X_pca, min_row_indices, axis=0)\n",
    "final_knn_test_y = np.delete(y, min_row_indices, axis=0)\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "# We loop over the different values of k and calculate the accuracy for each value of k.\n",
    "for kvalue in k_values:\n",
    "    # Predict labels for train set and test set\n",
    "    y_pred_train = knn(final_knn_train_X, final_knn_train_y, final_knn_train_X, kvalue)\n",
    "    y_pred_test = knn(final_knn_train_X, final_knn_train_y, final_knn_test_X, kvalue)\n",
    "    # Calculate accuracy\n",
    "    train_accuracies.append(accuracy(final_knn_train_y, y_pred_train))\n",
    "    test_accuracies.append(accuracy(final_knn_test_y, y_pred_test))\n",
    "\n",
    "print(\"Kmeans + kNN Results :\")\n",
    "print(\"Training Accuracy for Kmeans+knn for k = 1 : \" + str(train_accuracies[0]))\n",
    "print(\"Testing Accuracy for Kmeans+knn for k = 1 : \" + str(test_accuracies[0]))\n",
    "print(\"Training Accuracy for Kmeans+knn for k = 3 : \" + str(train_accuracies[1]))\n",
    "print(\"Testing Accuracy for Kmeans+knn for k = 3 : \" + str(test_accuracies[1]))\n",
    "print(\"Training Accuracy for Kmeans+knn for k = 5 : \" + str(train_accuracies[2]))\n",
    "print(\"Testing Accuracy for Kmeans+knn for k = 5 : \" + str(test_accuracies[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prateek/anaconda3/envs/AnacondaTest/lib/python3.11/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "/Users/prateek/anaconda3/envs/AnacondaTest/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:394: SparseEfficiencyWarning: splu converted its input to CSC format\n",
      "  warn('splu converted its input to CSC format', SparseEfficiencyWarning)\n",
      "/Users/prateek/anaconda3/envs/AnacondaTest/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:285: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
      "  warn('spsolve is more efficient when sparse b '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Clustering + kNN Results :\n",
      "Training Accuracy for Spectral+Kmeans+knn for k = 1 : 100.0\n",
      "Testing Accuracy for Spectral+Kmeans+knn for k = 1 : 78.8483547925608\n",
      "Training Accuracy for Spectral+Kmeans+knn for k = 3 : 81.0\n",
      "Testing Accuracy for Spectral+Kmeans+knn for k = 3 : 77.46638054363376\n",
      "Training Accuracy for Spectral+Kmeans+knn for k = 5 : 80.0\n",
      "Testing Accuracy for Spectral+Kmeans+knn for k = 5 : 76.13590844062948\n"
     ]
    }
   ],
   "source": [
    "cost = 100000000\n",
    "[sorted_eigen_values, k_eigen_vectors] = spectral_clustering_analysis(X_pca)\n",
    "for i in range(no_of_runs) :\n",
    "    #Using the Forgy seed method for initialisation : take K random datapoints from PCA-applied dataset\n",
    "    rs = 5*i\n",
    "    np.random.seed(rs)\n",
    "    initial_centroid_indices = np.random.choice(num_samples, K_d_cluster_size, replace=False)\n",
    "    centroids = k_eigen_vectors[initial_centroid_indices][:]\n",
    "    #print(centroids.shape)\n",
    "    [final_kmeans_centroids, new_cost] = run_kmeans(K_d_cluster_size, centroids, k_eigen_vectors)\n",
    "    #print(cost)\n",
    "    if cost > new_cost :\n",
    "        cost = new_cost\n",
    "        final_centroids = final_kmeans_centroids.copy()\n",
    "distance_matrix = get_distance_matrix(k_eigen_vectors, final_centroids)\n",
    "min_row_indices = np.argmin(distance_matrix, axis=0)\n",
    "final_knn_train_X = k_eigen_vectors[min_row_indices][:]\n",
    "final_knn_train_y = y[min_row_indices][:]\n",
    "final_knn_test_X = np.delete(k_eigen_vectors, min_row_indices, axis=0)\n",
    "final_knn_test_y = np.delete(y, min_row_indices, axis=0)\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "# We loop over the different values of k and calculate the accuracy for each value of k.\n",
    "for kvalue in k_values:\n",
    "    # Predict labels for train set and test set\n",
    "    y_pred_train = knn(final_knn_train_X, final_knn_train_y, final_knn_train_X, kvalue)\n",
    "    y_pred_test = knn(final_knn_train_X, final_knn_train_y, final_knn_test_X, kvalue)\n",
    "    # Calculate accuracy\n",
    "    train_accuracies.append(accuracy(final_knn_train_y, y_pred_train))\n",
    "    test_accuracies.append(accuracy(final_knn_test_y, y_pred_test))\n",
    "\n",
    "print(\"Spectral Clustering + kNN Results :\")\n",
    "print(\"Training Accuracy for Spectral+Kmeans+knn for k = 1 : \" + str(train_accuracies[0]))\n",
    "print(\"Testing Accuracy for Spectral+Kmeans+knn for k = 1 : \" + str(test_accuracies[0]))\n",
    "print(\"Training Accuracy for Spectral+Kmeans+knn for k = 3 : \" + str(train_accuracies[1]))\n",
    "print(\"Testing Accuracy for Spectral+Kmeans+knn for k = 3 : \" + str(test_accuracies[1]))\n",
    "print(\"Training Accuracy for Spectral+Kmeans+knn for k = 5 : \" + str(train_accuracies[2]))\n",
    "print(\"Testing Accuracy for Spectral+Kmeans+knn for k = 5 : \" + str(test_accuracies[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Sampling + kNN Results :\n",
      "Training Accuracy for RS+knn for k = 1 : 100.0\n",
      "Testing Accuracy for RS+knn for k = 1 : 73.03719599427754\n",
      "Training Accuracy for RS+knn for k = 3 : 87.0\n",
      "Testing Accuracy for RS+knn for k = 3 : 68.42346208869814\n",
      "Training Accuracy for RS+knn for k = 5 : 83.0\n",
      "Testing Accuracy for RS+knn for k = 5 : 67.6752503576538\n"
     ]
    }
   ],
   "source": [
    "row_indices = np.random.choice(num_samples, K_d_cluster_size, replace=False)\n",
    "final_knn_train_X = X_pca[row_indices][:]\n",
    "final_knn_train_y = y[row_indices][:]\n",
    "final_knn_test_X = np.delete(X_pca, row_indices, axis=0)\n",
    "final_knn_test_y =np.delete(y, row_indices, axis=0)\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "# We loop over the different values of k and calculate the accuracy for each value of k.\n",
    "for kvalue in k_values:\n",
    "    # Predict labels for train set and test set\n",
    "    y_pred_train = knn(final_knn_train_X, final_knn_train_y, final_knn_train_X, kvalue)\n",
    "    y_pred_test = knn(final_knn_train_X, final_knn_train_y, final_knn_test_X, kvalue)\n",
    "    # Calculate accuracy\n",
    "    train_accuracies.append(accuracy(final_knn_train_y, y_pred_train))\n",
    "    test_accuracies.append(accuracy(final_knn_test_y, y_pred_test))\n",
    "\n",
    "print(\"Random Sampling + kNN Results :\")\n",
    "print(\"Training Accuracy for RS+knn for k = 1 : \" + str(train_accuracies[0]))\n",
    "print(\"Testing Accuracy for RS+knn for k = 1 : \" + str(test_accuracies[0]))\n",
    "print(\"Training Accuracy for RS+knn for k = 3 : \" + str(train_accuracies[1]))\n",
    "print(\"Testing Accuracy for RS+knn for k = 3 : \" + str(test_accuracies[1]))\n",
    "print(\"Training Accuracy for RS+knn for k = 5 : \" + str(train_accuracies[2]))\n",
    "print(\"Testing Accuracy for RS+knn for k = 5 : \" + str(test_accuracies[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
